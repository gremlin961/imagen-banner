{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a331300-5ff3-4219-83c0-ce11703cc9e1",
   "metadata": {},
   "source": [
    "# How To Use Vertex Text-to-Image Generative AI To Build Dynamic Banners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34429b82-078c-4107-827d-8aaed4ab1121",
   "metadata": {},
   "source": [
    "This notebook outlines how to interact with Vertex AI's Text-to-Image GenAI models to create content for dynamic website banners. With Imagen on Vertex AI, developers can utilize next-generation AI products to transform their imagination into high quality visual assets, in seconds. With just some simple lines of Python, we can merge these assets with existing content to provide a new level of visual website content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed54ec-9f36-40af-8d2e-c6fd32a76222",
   "metadata": {},
   "source": [
    "## Prepare the python development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ce888-8c52-476b-96d0-7f65cb259f8d",
   "metadata": {},
   "source": [
    "First, let's identify any project specific variables to customize this notebook to your GCP environment. Change YOUR_PROJECT_ID with your own GCP project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205088b5-6d5b-46dd-9d77-a8352eac630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"rkiles-demo-host-vpc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75038c4-0365-4c03-a38c-21316392dad8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92738a-045b-48a4-ab0e-1d98fad2089a",
   "metadata": {},
   "source": [
    "Install any needed python modules from our requirements.txt file. Most Vertex Workbench environments include all the packages we'll be using, but if you are using an external Jupyter Notebook or require any additional packages for your own needs, you can simply add them to the included requirements.txt file an run the folloiwng commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69175b8-63c4-4b5a-837d-055743c0b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b2ce7-0277-4ada-9648-34c67774bfd2",
   "metadata": {},
   "source": [
    "Now we will import all required modules. For our purpose, we will be utilizing the following:\n",
    "\n",
    "- google.auth - Provides authentication access to the Google API's, such as imagegeneration:predict\n",
    "- PIL - An easy to use Python image library to help build the background for our banner and perform image layering\n",
    "- io - Core python libray used to work with I/O. We will use this to help convert strings to byte objects for PIL\n",
    "- base64 - Imagen API requests return generated or edited images as base64-encoded strings. This module will help us decode this data to an image file\n",
    "- requests - This module will allow us to interact directly with Imagen over the REST API. \n",
    "- json - Python module used to interact with JSON data. Imagen returns results in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e15897-0cb0-4173-9b91-17270a10b989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.auth.transport.requests\n",
    "import google.auth\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b2668-962a-42da-b92b-4932f224bb0d",
   "metadata": {},
   "source": [
    "## Authenticate to the Vertex AI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57a2c4-d51a-42b8-b0c7-24aced49d64b",
   "metadata": {},
   "source": [
    "Our Vertex Workbench instance is configured to use a specified service account that has IAM access to the text-to-vision API. The following two secitons will allow us to generate the access token we will pass as an authorization bearer token later in the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997bec4d-c8d6-4f90-9726-3e574ab061d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d12eb-fd5c-4c70-b278-6a199985f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = credentials.token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3fb974-e836-40c5-81e3-c83f63bc84e0",
   "metadata": {},
   "source": [
    "## Prepare the HTTP POST request to the REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93462b3-7ee7-4f6f-a141-0d54ce304669",
   "metadata": {},
   "source": [
    "Define the header fields, including the access token we created in the last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a6c60-9040-4f58-9d25-383e25b86360",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        'Authorization': 'Bearer ' + access_token,\n",
    "        'Content-Type': 'application/json; charset=utf-8'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a60a7-400c-4c54-989b-6e5a9b931711",
   "metadata": {},
   "source": [
    "You can uncomment the following line for troubleshooting if you want to see how the header will be passed to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4842b3-abb5-4941-b501-a78bd6341306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192001a-47ec-4a6b-a93e-f91ce2e1dd79",
   "metadata": {},
   "source": [
    "Next we will specifiy the URL for the Imagen REST API. You should have already specified the correct project ID in the very first step of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfea6f4-3cbd-413c-9996-3edd9ee944e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/imagegeneration:predict'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d82f2-ab09-4da5-ac82-6b659c765051",
   "metadata": {},
   "source": [
    "To use Imagen on Vertex AI you must provide a text description of what you want to generate or edit. These descriptions are called prompts, and these prompts are the primary way you communicate with Generative AI. Here, we are specifiying what we want the model to create using a prompt. Play around with this content and see what kind of images you can create. More information can be found here https://cloud.google.com/vertex-ai/docs/generative-ai/image/img-gen-prompt-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f16782-6804-4ea6-b44b-00ea66c05710",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_prompt = \"yellow handbag on a mountain top\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1980e70-eef9-49e7-a66e-e4c1bff5cd66",
   "metadata": {},
   "source": [
    "The REST API expects a json payload containing the data that will be used to generate the image. We are only passing a few of the available request options below, but you can find more information about the REST API and additional featuers here https://cloud.google.com/vertex-ai/docs/generative-ai/image/generate-images#-drest\n",
    "\n",
    "In this example, we are providing the prompt information from the last step and specifiying a single image sample to be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4152412-a31b-4fa2-aa0a-280f5115c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = '{\"instances\": [{\"prompt\": \"' + imagen_prompt + '\"}],\"parameters\": {\"sampleCount\": 1}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227aa1f-cfe3-42d7-8ffd-713934aef13b",
   "metadata": {},
   "source": [
    "Lastly, we will post the request to the Imagen REST API and wait for the requested image to be generated and returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561c8ec-cfbe-40c8-8fd1-b516d03ed545",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(url, data=request_body, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c44c6c-adcd-4418-b805-8be482304e1e",
   "metadata": {},
   "source": [
    "You can optionally uncomment the following to view the returned status code for verification or troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfcca9-20e4-477d-adfa-3cc66fc3c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea8b0f-41dc-457e-a23b-81e98abe6c5c",
   "metadata": {},
   "source": [
    "## Process the returned request and decode the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f2887-4e6a-444f-91d2-355b0ac47422",
   "metadata": {},
   "source": [
    "The Imagen API returns images in a base64 encoded JSON string. We will start by defining our data and then decoding the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8359a-fcc6-4952-9f4d-e35c356a4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f1523-4299-4bfb-9421-1bc9c4a91e43",
   "metadata": {},
   "source": [
    "You can optionally uncomment this line to see the full JSON payload returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc4511-f812-4c93-a0fb-00bb20691da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img_data[\"predictions\"][0][\"bytesBase64Encoded\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266e0a3-55e2-4999-92b5-27f161d1b059",
   "metadata": {},
   "source": [
    "We will be using just the first returned image sample in this example. The API can return up to 8 sample images, so you could insert a simple for loop here to iterate through multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3379a-7673-41ed-8ccc-3e08bfa22416",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_image = img_data[\"predictions\"][0][\"bytesBase64Encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a62b00-3838-474f-bcc9-b0186ecca318",
   "metadata": {},
   "source": [
    "This will decode the base64 string to a usable image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9300825-1aa7-4e30-add8-73521743abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_image = base64.b64decode(encoded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fb2de-7f4c-474e-9c97-fae090ae2973",
   "metadata": {},
   "source": [
    "Optionally uncomment this line to save the image to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d291d8-ecd7-465e-9b87-643e53e1eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"b64DecodedImage1.png\", \"wb\") as fh:\n",
    "#    fh.write(decoded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9067ee0-3860-4d7a-8a09-ab0156039678",
   "metadata": {},
   "source": [
    "We will be keeping this image in memory since we will be making further modifications before saving the final image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bf1e1-6efe-4891-a18a-9892538f7890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byte_stream = BytesIO(decoded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cf0a6-1cc6-4bc3-bcef-2ad299d12a1e",
   "metadata": {},
   "source": [
    "Let's view the returned iamge from Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95ff86-63b2-485c-aed6-604a51a46408",
   "metadata": {},
   "outputs": [],
   "source": [
    "genImage = Image.open(byte_stream).convert(\"RGBA\")\n",
    "genImage.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbb4fe-6646-4748-9d26-699f0725733a",
   "metadata": {},
   "source": [
    "## Create our background for the banner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d6e42-9ce4-4f73-86e4-5eb4f931a212",
   "metadata": {},
   "source": [
    "Our banner background will be a solid dark blue. Imagen generates images that are 1024x1024, so if we want our final banner to be 468x60, we will need to create our background at a size of 7987x1024 and then scale the final image down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b1a05-2b31-4fc6-96d9-6ccd695e3650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_background = Image.new(mode = \"RGBA\", size = (7987, 1024), color = (10, 60, 140))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4ff0d-eb06-4458-9f8a-ddfcc50c7510",
   "metadata": {},
   "source": [
    "Let's take a look at our new background. PIL creates a temporary jpeg for display purposes, so let's specify this as an RGB image to remove the alpha channels and avoid any error messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b134b9e-2ca1-432c-8845-dee715ec6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_background.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0fd48-6cda-4fb0-bd14-6ece71ad72d1",
   "metadata": {},
   "source": [
    "## Layer our banner images and create our final image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da583fa-0a8a-4f2b-a02d-2faf8bd5e028",
   "metadata": {},
   "source": [
    "Now we will define all of the images we will use in our final banner. These will consisting of our background, Imagen generated image, some sample text, and a corporate logo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46312d1f-0f47-4654-a21a-f846d11a73da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image1 = im_background\n",
    "image2 = Image.open(byte_stream).convert(\"RGBA\")\n",
    "image3 = Image.open(\"SSE-text.png\").convert(\"RGBA\")\n",
    "image4 = Image.open(\"corp-logo.png\").convert(\"RGBA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386dd5e-b494-41e6-9ad5-90f521585aa5",
   "metadata": {},
   "source": [
    "This section covers how we will layer the images over the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075c770-4b9d-4a2f-82ba-9337c8ae26e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image1.paste(image2, (100,0), mask = image2)\n",
    "image1.paste(image3, (1300,20), mask = image3)\n",
    "image1.paste(image4, (3500,200), mask = image4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21222899-24d5-4817-b1f9-0fd6002c2466",
   "metadata": {},
   "source": [
    "Lastly we will resize the final image to our target banner size and display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e7535-372b-4149-a66c-21711d5bdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image1.resize((468, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ba3e0-40ef-467c-8c35-3de6b4c1e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b0486-848d-4202-a2b7-823b6c8b2133",
   "metadata": {},
   "source": [
    "You can uncomment this line to save the final image to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dedd52-1592-4342-9c28-f5399f1751cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image1.save(\"result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e2d0b-8755-48c9-8d64-7a0ab8be5ac7",
   "metadata": {},
   "source": [
    "That's it! Congratulations on creating your first dynamic banner with Imagen!"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
